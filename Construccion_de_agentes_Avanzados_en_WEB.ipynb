{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelTroncoso/Agentes_Gratis/blob/main/Construccion_de_agentes_Avanzados_en_WEB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent"
      ],
      "metadata": {
        "id": "oKWpt41eMxfC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NlYaD7AMtFA"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "SwWf2tS6NIak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "N_NDsioiNLk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "search = TavilySearchResults(max_results=2)"
      ],
      "metadata": {
        "id": "3oZ_8q1SNNBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search.invoke(\"que es openai o1-mini\")"
      ],
      "metadata": {
        "id": "WqzfPQgcNOOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qU install faiss-gpu"
      ],
      "metadata": {
        "id": "_8Pz3e0NNPqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
        "docs = loader.load()\n",
        "\n",
        "documents = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ").split_documents(docs)\n",
        "\n",
        "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
        "retriever = vector.as_retriever()"
      ],
      "metadata": {
        "id": "5PIp_aJHNRDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"how to upload a dataset\")[0]"
      ],
      "metadata": {
        "id": "Pio7a_KWNSQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "txt = '''Busca información sobre LangSmith.\n",
        "¡Para cualquier pregunta sobre LangSmith,\n",
        "debes usar esta herramienta!'''\n",
        "\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"langsmith_search\",\n",
        "    txt,)"
      ],
      "metadata": {
        "id": "LS6FtwLGNT0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [search, retriever_tool]"
      ],
      "metadata": {
        "id": "ApXw_szqNVSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_tools = model.bind_tools(tools)"
      ],
      "metadata": {
        "id": "wDh5nKiaNX4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "id": "gbn0OL1oNbXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\n",
        "                            \"What's the weather in SF?\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "id": "C5cvyn29NdgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "prompt.messages"
      ],
      "metadata": {
        "id": "rDzwQhydNe7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "\n",
        "agent = create_tool_calling_agent(model, tools, prompt)"
      ],
      "metadata": {
        "id": "JzpxgTvcNgW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)"
      ],
      "metadata": {
        "id": "sDfNyOXcNiZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\": \"hi!\"})"
      ],
      "metadata": {
        "id": "UaJnHod_Njt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\": \"Cómo ayuda langsmith testing?\"})"
      ],
      "metadata": {
        "id": "nbfOXTDsNk39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_executor.invoke({\"input\": \"Como intalar LangSmith?\"})['output'])"
      ],
      "metadata": {
        "id": "LxFc8_8JNpNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
        "agent_executor.invoke({\"input\": \"Mi nombre es Bob\", \"chat_history\": []})"
      ],
      "metadata": {
        "id": "A1xoTwH2Nqp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"chat_history\": [\n",
        "            HumanMessage(content=\"Mi nombre es Bob\"),\n",
        "            AIMessage(content=\"Hola Bob! ¿En qué puedo ayudarte hoy?\"),\n",
        "        ],\n",
        "        \"input\": \"Cuál es mi nombre?\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "9j0JE_IDNsOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]"
      ],
      "metadata": {
        "id": "wAEu_hJCNtX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ],
      "metadata": {
        "id": "EBgAjYFXNv0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_with_chat_history.invoke(\n",
        "    {\"input\": \"what's my name?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
        ")"
      ],
      "metadata": {
        "id": "ywn--sJvNxTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumen\n",
        "¿Qué es un Agente en LangChain?\n",
        "Un agente es un sistema que utiliza un modelo de lenguaje como núcleo para tomar decisiones sobre qué acciones ejecutar y qué entradas proporcionar a esas acciones. Estos agentes pueden realizar tareas más complejas y específicas que las que se limitan a la generación de texto, ya que son capaces de:\n",
        "\n",
        "Interactuar con herramientas externas (APIs, bases de datos, web scraping, etc.).\n",
        "Tomar decisiones basadas en el contexto y las acciones previas.\n",
        "Restringir sus respuestas utilizando reglas, memoria de conversaciones previas o datos en tiempo real.\n",
        "Los agentes permiten controlar partes de código o acceder a información en tiempo real, lo que los hace mucho más útiles en aplicaciones que requieren integración con sistemas externos.\n",
        "\n",
        "Uso de Toolkits en Agentes\n",
        "En LangChain, los Toolkits son una colección de herramientas que se pueden integrar con un agente para que este realice acciones específicas. Cada tool (herramienta) puede conectarse a un servicio externo o sistema y actuar como un intermediario entre el modelo de lenguaje y la información que se necesita.\n",
        "\n",
        "En este proyecto, estamos utilizando Tabli Search, una herramienta para realizar búsquedas en internet en tiempo real. Esto permite que el agente obtenga información actualizada sobre cualquier tema que se necesite, lo cual es ideal para consultas dinámicas o casos donde el modelo por sí solo no tenga acceso a datos específicos.\n",
        "\n",
        "Ejemplo: Si el agente necesita obtener información reciente sobre un modelo de OpenAI, como el O1-Mini, puede utilizar Tabli Search para hacer la consulta, buscar en fuentes externas, y devolver una respuesta basada en los resultados encontrados.\n",
        "\n",
        "Cómo Funcionan los Agentes con Múltiples Herramientas\n",
        "En este caso, hemos combinado el uso de Tabli Search con un Retriever Tool. Esta segunda herramienta utiliza una base vectorial para almacenar y recuperar documentos fragmentados (como páginas web o PDFs) que ya hemos cargado y vectorizado.\n",
        "\n",
        "El flujo general es el siguiente:\n",
        "\n",
        "Input del Usuario: El agente recibe una consulta del usuario.\n",
        "Elección de Herramienta: Basado en la naturaleza de la pregunta, el agente decide si utilizar su base de conocimientos local (almacenada en la base vectorial) o realizar una búsqueda en la web usando Tabli Search.\n",
        "Búsqueda y Respuesta: Si es necesario, el agente hace la búsqueda y genera una respuesta utilizando las herramientas seleccionadas.\n",
        "Respuesta Final: El modelo de lenguaje, integrado con las herramientas, procesa los resultados y genera una respuesta para el usuario.\n",
        "Este enfoque permite que el agente sea más versátil y útil, pudiendo manejar tanto información almacenada previamente como datos obtenidos en tiempo real.\n",
        "\n",
        "Integración de la Base Vectorial\n",
        "La base vectorial permite al agente almacenar y buscar en documentos previamente vectorizados (convertidos en representaciones numéricas llamadas embeddings). Cada vez que un usuario hace una pregunta, el agente puede buscar en esta base vectorial para recuperar información relevante, que luego se procesa junto con los resultados de las búsquedas en internet.\n",
        "\n",
        "Vectorización: Este proceso convierte los documentos (como PDFs o sitios web) en vectores, que son representaciones numéricas del contenido semántico. Esto permite realizar búsquedas por similitud en los documentos cargados. Los vectores similares se encuentran cerca en el espacio vectorial, lo que permite recuperar información relevante rápidamente.\n",
        "\n",
        "Construcción del Prompt para el Agente\n",
        "En este proyecto, el agente tiene un prompt personalizado que define cómo debe comportarse. El System Prompt indica las reglas que el agente debe seguir, como consultar los documentos o utilizar Tabli Search para información externa. Este prompt también define cómo debe interactuar con las diferentes herramientas disponibles y cómo estructurar las respuestas para los usuarios.\n",
        "\n"
      ],
      "metadata": {
        "id": "eMV-bj74v1LZ"
      }
    }
  ]
}