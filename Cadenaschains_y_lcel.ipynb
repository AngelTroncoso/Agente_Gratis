{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelTroncoso/Agentes_Gratis/blob/main/Cadenaschains_y_lcel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "DKfpyTKQDwfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumen  \n",
        "LangChain Expression Language (LCEL) es una forma declarativa de construir y gestionar cadenas de procesos dentro de LangChain. Este enfoque simplifica la creación de flujos de trabajo complejos al permitir la combinación de diferentes componentes, como modelos de lenguaje, herramientas y parsers, en una secuencia lógica. Esta técnica es especialmente útil cuando trabajas con aplicaciones que requieren procesamiento de lenguaje natural, flujos asincrónicos o ejecución de múltiples tareas en paralelo.\n",
        "\n",
        "1. Cadenas en LangChain\n",
        "En LangChain, las cadenas (chains) representan una secuencia de pasos que se conectan entre sí, creando un flujo de procesamiento que puede incluir desde la generación de texto hasta la ejecución de operaciones complejas, como traducciones, búsquedas en internet o invocaciones de herramientas externas.\n",
        "\n",
        "LCEL facilita la construcción de estas cadenas al ofrecer un lenguaje que conecta los distintos componentes usando una sintaxis clara, donde cada paso se une al siguiente mediante el uso de una barra vertical |. Esto permite que los desarrolladores estructuren flujos que combinen diferentes funciones, como el uso de un Prompt Template para definir las instrucciones y un Large Language Model para generar respuestas.\n",
        "\n",
        "2. Soporte para Características Avanzadas\n",
        "LCEL no solo se limita a encadenar componentes, sino que también soporta características avanzadas, como:\n",
        "\n",
        "Streaming: Permite que las respuestas se generen de manera progresiva, tal como ocurre en plataformas de generación de texto como ChatGPT. En lugar de recibir una respuesta completa al final, el texto se despliega letra por letra o palabra por palabra, mejorando la experiencia del usuario al hacerla más interactiva.\n",
        "Ejecución paralela y asincronía: LCEL es capaz de ejecutar múltiples tareas al mismo tiempo, lo cual es útil cuando necesitas realizar varias consultas o procesos en paralelo, optimizando el rendimiento y reduciendo el tiempo de espera.\n",
        "Trazabilidad con LangSmith: LangSmith ofrece herramientas para hacer un seguimiento detallado de cada paso de una cadena, lo que facilita la depuración y mejora la visibilidad de cómo los datos fluyen a través del sistema.\n",
        "3. Estructura de una Cadena con LCEL\n",
        "La estructura básica de una cadena en LCEL consiste en conectar diversos elementos como prompts, modelos de lenguaje y parsers. Un ejemplo típico puede incluir un Prompt Template para generar instrucciones, un Large Language Model para procesar el texto, y un Output Parser para formatear la salida de manera más útil.\n",
        "\n",
        "En el ejemplo proporcionado, se construyó una cadena para traducir un texto utilizando un Prompt Template que indicaba al modelo qué hacer (traducir una palabra), seguido de un Output Parser para convertir la respuesta en un formato adecuado (en este caso, texto plano).\n",
        "\n",
        "Esta cadena se define uniendo los componentes de la siguiente manera:\n",
        "\n",
        "Prompt Template: Se encarga de estructurar la petición que se le hará al modelo, como “traducir una palabra a otro idioma”.\n",
        "Large Language Model: Procesa la solicitud y genera una respuesta. En el caso de traducciones, esto podría ser GPT-4 o cualquier otro modelo de lenguaje.\n",
        "Output Parser: Mejora la salida, formateando la respuesta en el formato deseado (en este caso, un string con la traducción).\n",
        "4. Output Parsers\n",
        "Los Output Parsers son una herramienta clave para refinar la salida generada por el modelo. Estos parsers se encargan de tomar la respuesta del modelo y darle un formato adecuado antes de devolverla al usuario. Existen diferentes tipos de parsers según el tipo de salida que necesites:\n",
        "\n",
        "String Output Parser: Convierte la salida en una cadena de texto simple.\n",
        "JSON Parser: Convierte la respuesta en un formato estructurado como JSON, lo cual es útil cuando se requiere una salida más detallada y organizada.\n",
        "Custom Parsers: También puedes crear parsers personalizados que adapten la salida a las necesidades específicas de tu aplicación.\n",
        "Los parsers juegan un papel crucial cuando necesitas garantizar que la respuesta siga un formato consistente, como en tareas de traducción, resumen o clasificación.\n",
        "\n",
        "5. Añadiendo Streaming a la Cadena\n",
        "El streaming es una funcionalidad que añade dinamismo a la interacción, mostrando la respuesta generada de manera progresiva en lugar de presentarla completa al final. Esto mejora la experiencia del usuario, haciendo que la interacción sea más fluida y parecida a una conversación en tiempo real. Implementar streaming en LangChain es una forma de hacer que las respuestas sean más interactivas, especialmente útil en aplicaciones conversacionales o en chatbots.\n",
        "\n",
        "6. Aplicaciones de LCEL\n",
        "LangChain Expression Language puede ser aplicado en una variedad de casos, desde aplicaciones simples como chatbots, hasta flujos de trabajo más complejos que integran múltiples herramientas. Algunos ejemplos incluyen:\n",
        "\n",
        "Asistentes Virtuales: Al combinar prompts, modelos de lenguaje y herramientas externas, puedes crear un asistente que procese información, realice consultas en internet, y responda a preguntas en tiempo real.\n",
        "Traducción Automatizada: Utilizando un prompt template, un modelo de lenguaje, y un parser, puedes construir un sistema que reciba texto en un idioma y lo devuelva traducido automáticamente a otro.\n",
        "Aplicaciones Multitarea: Gracias a la ejecución paralela y asincrónica, puedes crear aplicaciones que realicen múltiples tareas simultáneamente, como buscar información en varias bases de datos a la vez, o consultar distintas APIs de manera eficiente.\n",
        "LangChain Expression Language es una herramienta poderosa y flexible que simplifica la construcción de cadenas complejas en LangChain. Su sintaxis declarativa permite integrar múltiples componentes en un flujo continuo, lo que mejora la capacidad para crear aplicaciones avanzadas que aprovechan lo mejor de los modelos de lenguaje y herramientas externas.\n",
        "\n",
        "LCEL facilita el manejo de tareas avanzadas como la traducción automática, el procesamiento de texto y la ejecución en paralelo, ofreciendo una solución ideal para quienes buscan optimizar el rendimiento y la precisión de sus aplicaciones. Con características como streaming y trazabilidad, LangChain ofrece un marco completo para desarrollar aplicaciones inteligentes y escalables."
      ],
      "metadata": {
        "id": "C8WReP3PVAFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai langchain"
      ],
      "metadata": {
        "id": "tsF42ACvDw8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "VfzpRGFxDyx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obOEapTnDdOz"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    ('system', \"Traduce lo siguiente al {language}: \"),\n",
        "    ('human', '{text}')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "chain = prompt_template | model | parser"
      ],
      "metadata": {
        "id": "Ogs6AHojD0yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke({'language': 'Italian', 'text': 'hello'})"
      ],
      "metadata": {
        "id": "f5St214VD2aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "zp-_ddXlD39R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}